---
layout: post
title:  "GATSBI: Generative Adversarial Training for Simulation-Based Inference"
date:   2022-08-23
categories: paper
speaker: Michael J. Williams
---

At this meeting we discussed GATSBI, an algorithm for simulation-based inference that uses GANs. The main selling point if this approach is its ability to perform inference in high-dimensional space.

## Abstract - GATSBI: Generative Adversarial Training for Simulation-Based Inference

> Simulation-based inference (SBI) refers to statistical inference on stochastic models for which we can generate samples, but not compute likelihoods. Like SBI algorithms, generative adversarial networks (GANs) do not require explicit likelihoods. We study the relationship between SBI and GANs, and introduce GATSBI, an adversarial approach to SBI. GATSBI reformulates the variational objective in an adversarial setting to learn implicit posterior distributions. Inference with GATSBI is amortised across observations, works in high-dimensional posterior spaces and supports implicit priors. We evaluate GATSBI on two SBI benchmark problems and on two high-dimensional simulators. On a model for wave propagation on the surface of a shallow water body, we show that GATSBI can return well-calibrated posterior estimates even in high dimensions. On a model of camera optics, it infers a high-dimensional posterior given an implicit prior, and performs better than a state-of-the-art SBI approach. We also show how GATSBI can be extended to perform sequential posterior estimation to focus on individual observations. Overall, GATSBI opens up opportunities for leveraging advances in GANs to perform Bayesian inference on high-dimensional simulation-based models.

## Links

* GATSBI: Generative Adversarial Training for Simulation-Based Inference - [arXiv](https://arxiv.org/abs/2203.06481) [OpenReview](https://openreview.net/forum?id=kR1hC6j48Tp)
* Official implementation - [GitHub](https://github.com/mackelab/gatsbi)
